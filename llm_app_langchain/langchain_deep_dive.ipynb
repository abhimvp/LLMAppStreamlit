{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0ac3701",
   "metadata": {},
   "source": [
    "# Deep Dive into Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ac20f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to learn Python_Langchain\n",
      "This is a test for Langchain\n"
     ]
    }
   ],
   "source": [
    "msg = \"Welcome to learn Python_Langchain\"\n",
    "print(msg)\n",
    "print(\"This is a test for Langchain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ef33ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain\n",
      "Version: 0.3.23\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: c:\\Users\\abhis\\Desktop\\AIAgents\\LLMAppStreamlit\\env\\Lib\\site-packages\n",
      "Requires: langchain-core, langchain-text-splitters, langsmith, pydantic, PyYAML, requests, SQLAlchemy\n",
      "Required-by: langchain-community\n",
      "---\n",
      "Name: langchain\n",
      "Version: 0.3.23\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: c:\\Users\\abhis\\Desktop\\AIAgents\\LLMAppStreamlit\\env\\Lib\\site-packages\n",
      "Requires: langchain-core, langchain-text-splitters, langsmith, pydantic, PyYAML, requests, SQLAlchemy\n",
      "Required-by: langchain-community\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Package(s) not found: #, check, installed, is, to, whether\n"
     ]
    }
   ],
   "source": [
    "pip show langchain # to check whether langchain is installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccee80d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain-google-genai\n",
      "Version: 2.1.2\n",
      "Summary: An integration package connecting Google's genai package and LangChain\n",
      "Home-page: https://github.com/langchain-ai/langchain-google\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: c:\\Users\\abhis\\Desktop\\AIAgents\\LLMAppStreamlit\\env\\Lib\\site-packages\n",
      "Requires: filetype, google-ai-generativelanguage, langchain-core, pydantic\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show langchain-google-genai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08182837",
   "metadata": {},
   "source": [
    "### Python-dotenv\n",
    "Python-dotenv is a python module that allows you to specify environment variables as key value pairs in a .env file within your python project directory.It is a convinient and secure way to load and use environment variables in your application.We can have more than one API key and will save them all in .env.\n",
    "- In this project, we will have an API key for Google's GEMINI, another one for pinecone , Hugging Face and so on.\n",
    "- create an API Key to access google GEMINI models - [go here](https://aistudio.google.com/app/apikey) & copy the API KEY and save it to our .env file , which we will create.\n",
    "- let's load environment varaibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdc3d2e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from dotenv import load_dotenv , find_dotenv\n",
    "# load the .env file\n",
    "load_dotenv(find_dotenv(),override=True)\n",
    "# to get the value of an environment variable\n",
    "# os.environ.get('GOOGLE_API_KEY') - display the key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c29215",
   "metadata": {},
   "source": [
    "- We know that langchain provides a standard interface for interacting with various LLMs, including openAI's GPT models , Google's GEMINI, Meta's LLAMA ..etc\n",
    "- In Langchain terminology these are called LLM providers.\n",
    "- `Let's see how to invoke the models like Google GEMINI.`\n",
    "- The models expose an interface where chat messages or conversations serve as inputs & outputs\n",
    "- refer this [documentation](https://ai.google.dev/gemini-api/docs) to understand more on what to use and how to use like chat-completions.\n",
    "- [Multi-turn conversation](https://ai.google.dev/gemini-api/docs/text-generation#multi-turn-conversations) & [system instructions](https://ai.google.dev/gemini-api/docs/text-generation#system-instructions) - System instructions let you steer the behavior of a model based on your specific use case. When you provide system instructions, you give the model additional context to help it understand the task and generate more customized responses. The model should adhere to the system instructions over the full interaction with the user, enabling you to specify product-level behavior separate from the prompts provided by end users.\n",
    "- from langchain we use [messages](https://python.langchain.com/api_reference/core/messages.html) - Messages are objects used in prompts and chat conversations.\n",
    "- like below:\n",
    "```py\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=\"You are a helpful assistant! Your name is Bob.\"\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=\"What is your name?\"\n",
    "    )\n",
    "]\n",
    "# Instantiate a chat model and invoke it with the messages\n",
    "model = ...\n",
    "print(model.invoke(messages))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c93ff60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Virat Kohli combines classical textbook technique with aggressive intent and unwavering mental fortitude to consistently dominate bowlers across all formats.\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n",
    "output = llm.invoke(\"explain virat kohli's batting style in one sentence\")\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47710000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(ChatGoogleGenerativeAI) \n",
    "# - gives whole documentation stuff on this library \n",
    "# like Help on class ChatGoogleGenerativeAI in module langchain_google_genai.chat_models: ....etc\n",
    "# we can see the default models and temparature and other parameters in the documentation is set to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "078848e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of India is New Delhi.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run-94872e41-a6b2-4a51-b099-aaf00334c829-0', usage_metadata={'input_tokens': 12, 'output_tokens': 9, 'total_tokens': 21, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage,SystemMessage,AIMessage\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant\"),\n",
    "    HumanMessage(content=\"What is the capital of India?\")\n",
    "]\n",
    "llm.invoke(messages)\n",
    "# print(assistant_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a4e089",
   "metadata": {},
   "source": [
    "- so above we can see that we're passing how the LLM to behave by using Messages(AI,System,Human) to let llm understand what it needs to do and respond accordingly.\n",
    "- [SystemMessage](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.system.SystemMessage.html) - Message for priming AI behavior. The system message is usually passed in as the first of a sequence of input messages.`Pass in content as positional arg.`\n",
    "- [HumanMessage](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.human.HumanMessage.html) - Message from a human. HumanMessages are messages that are passed in from a human to the model.\n",
    "- [AIMessage](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.ai.AIMessage.html) - Message from an AI.`AIMessage is returned from a chat model as a response to a prompt`.This message represents the output of the model and consists of both the raw output as returned by the model together standardized fields (e.g., tool calls, usage metadata) added by the LangChain framework.\n",
    "- this is how the `actual` assistant_response from above looks like which returns the AIMessage.\n",
    "```py\n",
    "AIMessage(content='The capital of India is New Delhi.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run-94872e41-a6b2-4a51-b099-aaf00334c829-0', usage_metadata={'input_tokens': 12, 'output_tokens': 9, 'total_tokens': 21, 'input_token_details': {'cache_read': 0}})\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9056318",
   "metadata": {},
   "source": [
    "### Caching in LangChain\n",
    "- we use caching in langchain to boost performance & save costs.\n",
    "    - Caching is the practice of storing frequently accessed data or results in a temporary, faster storage layer.\n",
    "    - In the context of LLM, Caching optimizes interactions with LLMs by reducing API calls and speeding up applications, resulting in a more efficient user experience.When you repeatedly request the same completion from an LLM, caching ensures that the result is stored locally.Subsequent requests for the same input can then be served directly from the cache, reducing the number of expensive API calls to the LLM provider.\n",
    "    - By avoiding redundant API calls, caching significantly speeds up your application, whether you are building chatbots,content generators or any other language related tools, faster-responses enhance the user experience.\n",
    "    - let's see how it's done in [langchain](https://python.langchain.com/api_reference/core/caches.html).which provides two options - 1-[in-memory cache](https://python.langchain.com/api_reference/core/caches/langchain_core.caches.InMemoryCache.html#langchain_core.caches.InMemoryCache) & 2-SQLlite-cache - [cache api reference](https://python.langchain.com/api_reference/langchain/globals.html) & we can find related examples in the official documentation on how to use this - [in our case](https://python.langchain.com/docs/how_to/llm_caching/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685399ac",
   "metadata": {},
   "source": [
    "#### In-Memory Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e4957ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_llm_cache\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm_cache=ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3653f6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 2.47 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Why did the JavaScript developer quit their job and start learning Python?\\n\\nBecause they heard Python was great for \"Data Handling\" and they were tired of always having to deal with \"Undefined.\"', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run-ae512894-2ea9-4c9b-8a4a-07aae309f658-0', usage_metadata={'input_tokens': 8, 'output_tokens': 39, 'total_tokens': 47, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "# to check the time taken to run the code\n",
    "from langchain_core.caches import InMemoryCache #Cache that stores things in memory.\n",
    "set_llm_cache(InMemoryCache()) #set the cache to be in memory\n",
    "prompt= \"tell me a joke about python & javascript\"\n",
    "llm_cache.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a622efed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 6.75 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Why did the JavaScript developer quit their job and start learning Python?\\n\\nBecause they heard Python was great for \"Data Handling\" and they were tired of always having to deal with \"Undefined.\"', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run-ae512894-2ea9-4c9b-8a4a-07aae309f658-0', usage_metadata={'input_tokens': 8, 'output_tokens': 39, 'total_tokens': 47, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# let's make the same request again to check the memory cache\n",
    "llm_cache.invoke(prompt) # this time it will be faster as it is in memory cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d30a8ce",
   "metadata": {},
   "source": [
    "- Above we can see the difference in time taken to run the code & how caching works to speed up the process.\n",
    "- let's see [SQLite](https://python.langchain.com/docs/how_to/llm_caching/#sqlite-cache) Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c3c1e538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 5.47 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Virat Kohli is an Indian international cricketer and former captain of the Indian national cricket team. He is widely regarded as one of the greatest batsmen of all time. Here's a breakdown of his key aspects:\\n\\n**Key Facts and Achievements:**\\n\\n*   **Full Name:** Virat Kohli\\n*   **Nickname:** Cheeku\\n*   **Date of Birth:** November 5, 1988\\n*   **Place of Birth:** Delhi, India\\n*   **Batting Style:** Right-handed\\n*   **Bowling Style:** Right-arm medium\\n*   **Role:** Top-order batsman\\n*   **Teams:** India, Royal Challengers Bangalore (IPL), Delhi (Domestic)\\n*   **Captaincy:** Former captain of the Indian national team across all formats.\\n*   **ICC Rankings:** Consistently ranked among the top batsmen in the world.\\n\\n**Major Achievements and Records:**\\n\\n*   **Most Runs in T20 Internationals:** He is the leading run-scorer in T20 International cricket.\\n*   **Most Centuries for India:** He has the second-most international centuries overall, behind Sachin Tendulkar.\\n*   **Fastest to 8,000, 9,000, 10,000, 11,000, and 12,000 ODI Runs:** Kohli holds the record for being the fastest to reach these milestones in One Day International (ODI) cricket.\\n*   **Captaincy Records:** As captain, he led India to the top of the ICC Test rankings and achieved significant success in ODI and T20I cricket. He is India's most successful Test captain.\\n*   **Awards:** Numerous awards including ICC ODI Player of the Year, Sir Garfield Sobers Trophy (ICC Cricketer of the Year), Arjuna Award, Padma Shri, and Rajiv Gandhi Khel Ratna (now Major Dhyan Chand Khel Ratna Award).\\n\\n**Playing Style and Strengths:**\\n\\n*   **Aggressive and Driven:** Kohli is known for his aggressive batting style and his intense passion for the game.\\n*   **Excellent Technique:** Possesses a solid technique that allows him to adapt to different formats and conditions.\\n*   **Consistent Run-Scorer:** Remarkably consistent across all formats of the game.\\n*   **Master of the Chase:** Renowned for his ability to chase down targets in limited-overs cricket.\\n*   **Fitness and Dedication:** Sets high standards for fitness and is known for his dedication to training.\\n\\n**Career Highlights:**\\n\\n*   **Under-19 World Cup Victory (2008):** Captained the Indian Under-19 team to victory in the 2008 World Cup.\\n*   **ODI Debut (2008):** Made his ODI debut for India against Sri Lanka.\\n*   **Test Debut (2011):** Made his Test debut for India against West Indies.\\n*   **World Cup Winner (2011):** Was part of the Indian team that won the 2011 Cricket World Cup.\\n*   **Champions Trophy Winner (2013):** Was part of the Indian team that won the 2013 ICC Champions Trophy.\\n\\n**Controversies:**\\n\\n*   Kohli has had his share of controversies, including on-field altercations and disagreements with cricket boards. However, he has generally matured over time.\\n\\n**Personal Life:**\\n\\n*   Married to Bollywood actress Anushka Sharma. They have a daughter named Vamika.\\n*   Known for his philanthropic work through the Virat Kohli Foundation.\\n\\n**Current Status:**\\n\\n*   Virat Kohli continues to be a key player for the Indian cricket team in all formats. While he has relinquished the captaincy, his experience and batting prowess remain invaluable. He still holds a very high profile in the sport.\\n\\nIn summary, Virat Kohli is a modern-day cricket icon known for his exceptional batting skills, aggressive leadership, and unwavering dedication to the game. His achievements and records speak for themselves, solidifying his place among the legends of cricket.\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run-f44c15cb-8bd8-4c6b-a848-15f7aaf01670-0', usage_metadata={'input_tokens': 7, 'output_tokens': 862, 'total_tokens': 869, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# We can do the same thing with a SQLite cache\n",
    "from langchain_community.cache import SQLiteCache\n",
    "\n",
    "set_llm_cache(SQLiteCache(database_path=\".langchain.db\"))\n",
    "# First request(not in cache, takes longer)\n",
    "llm_cache.invoke(\"Tell me about virat kohli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ddc16623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 1.35 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Virat Kohli is an Indian international cricketer and former captain of the Indian national cricket team. He is widely regarded as one of the greatest batsmen of all time. Here's a breakdown of his key aspects:\\n\\n**Key Facts and Achievements:**\\n\\n*   **Full Name:** Virat Kohli\\n*   **Nickname:** Cheeku\\n*   **Date of Birth:** November 5, 1988\\n*   **Place of Birth:** Delhi, India\\n*   **Batting Style:** Right-handed\\n*   **Bowling Style:** Right-arm medium\\n*   **Role:** Top-order batsman\\n*   **Teams:** India, Royal Challengers Bangalore (IPL), Delhi (Domestic)\\n*   **Captaincy:** Former captain of the Indian national team across all formats.\\n*   **ICC Rankings:** Consistently ranked among the top batsmen in the world.\\n\\n**Major Achievements and Records:**\\n\\n*   **Most Runs in T20 Internationals:** He is the leading run-scorer in T20 International cricket.\\n*   **Most Centuries for India:** He has the second-most international centuries overall, behind Sachin Tendulkar.\\n*   **Fastest to 8,000, 9,000, 10,000, 11,000, and 12,000 ODI Runs:** Kohli holds the record for being the fastest to reach these milestones in One Day International (ODI) cricket.\\n*   **Captaincy Records:** As captain, he led India to the top of the ICC Test rankings and achieved significant success in ODI and T20I cricket. He is India's most successful Test captain.\\n*   **Awards:** Numerous awards including ICC ODI Player of the Year, Sir Garfield Sobers Trophy (ICC Cricketer of the Year), Arjuna Award, Padma Shri, and Rajiv Gandhi Khel Ratna (now Major Dhyan Chand Khel Ratna Award).\\n\\n**Playing Style and Strengths:**\\n\\n*   **Aggressive and Driven:** Kohli is known for his aggressive batting style and his intense passion for the game.\\n*   **Excellent Technique:** Possesses a solid technique that allows him to adapt to different formats and conditions.\\n*   **Consistent Run-Scorer:** Remarkably consistent across all formats of the game.\\n*   **Master of the Chase:** Renowned for his ability to chase down targets in limited-overs cricket.\\n*   **Fitness and Dedication:** Sets high standards for fitness and is known for his dedication to training.\\n\\n**Career Highlights:**\\n\\n*   **Under-19 World Cup Victory (2008):** Captained the Indian Under-19 team to victory in the 2008 World Cup.\\n*   **ODI Debut (2008):** Made his ODI debut for India against Sri Lanka.\\n*   **Test Debut (2011):** Made his Test debut for India against West Indies.\\n*   **World Cup Winner (2011):** Was part of the Indian team that won the 2011 Cricket World Cup.\\n*   **Champions Trophy Winner (2013):** Was part of the Indian team that won the 2013 ICC Champions Trophy.\\n\\n**Controversies:**\\n\\n*   Kohli has had his share of controversies, including on-field altercations and disagreements with cricket boards. However, he has generally matured over time.\\n\\n**Personal Life:**\\n\\n*   Married to Bollywood actress Anushka Sharma. They have a daughter named Vamika.\\n*   Known for his philanthropic work through the Virat Kohli Foundation.\\n\\n**Current Status:**\\n\\n*   Virat Kohli continues to be a key player for the Indian cricket team in all formats. While he has relinquished the captaincy, his experience and batting prowess remain invaluable. He still holds a very high profile in the sport.\\n\\nIn summary, Virat Kohli is a modern-day cricket icon known for his exceptional batting skills, aggressive leadership, and unwavering dedication to the game. His achievements and records speak for themselves, solidifying his place among the legends of cricket.\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run-f44c15cb-8bd8-4c6b-a848-15f7aaf01670-0', usage_metadata={'input_tokens': 7, 'output_tokens': 862, 'total_tokens': 869, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Second request(in cache, takes no time)\n",
    "llm_cache.invoke(\"Tell me about virat kohli\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfaba8d",
   "metadata": {},
   "source": [
    "#### Streaming in Langchain\n",
    "\n",
    "- Streaming refers to the process of delivering the response in a continuous stream of data instead of sending the entire response at once.\n",
    "- This allows the user to receive the response piece by piece as it is generated, which can improve the user experience and reduce the overall latency.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cb575de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08871f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Verse 1)\n",
      "Silver disc hangs heavy in the velvet night\n",
      "Raven's silhouette against the pale moonlight\n",
      "He sits perched on the steeple, a feathered king\n",
      "Watching shadows dance and secrets the darkness bring\n",
      "He caws a mournful ballad, a lonely, haunting sound\n",
      "While the moon just stares down, spinning 'round and 'round\n",
      "\n",
      "(Chorus)\n",
      "Oh, Moon and Raven, celestial pair\n",
      "Lost in the darkness, breathing silent air\n",
      "One a beacon in the black, the other a soul in flight\n",
      "Forever bound together, in the lonely, endless night\n",
      "Moon and Raven, Moon and Raven, hear their lonely cry\n",
      "Echoing through the heavens, beneath a starless sky."
     ]
    }
   ],
   "source": [
    "prompt = \"write a rock song about the moon and a raven in 1 verses and a chorus\"\n",
    "for chunk in llm.stream(prompt):\n",
    "    print(chunk.content, end=\"\",flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68cc4f2",
   "metadata": {},
   "source": [
    "#### Prompt templates\n",
    "\n",
    "A prompt refers to the input to the model.\n",
    "\n",
    "- Prompt templates are a way to create dynamic prompts for LLMs.\n",
    "- `A prompt template takes a piece of text and injects a user's input into that piece of text.`\n",
    "- In LangChain there are `PromptTemplates` and `ChatPromptTemplates`.\n",
    "    - [promptTemplates](https://python.langchain.com/docs/concepts/prompt_templates/) are used for tasks that involve generating text such as answering questions or completing sentences, while [chat prompt templates](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html) are specifically for tasks that involve engaging in conversations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed286918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nYou're an experienced software engineer.\\nYour task is to explain the use of decorators in python code in a simple way.\\nThe explanation should be clear and concise, using simple language and examples if necessary.\\nIn few lines alone is fine.don't give long responses.\\nThe explanation should be easy to understand for someone who is not familiar with the concept.\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prompt templates help to translate user input and parameters into instructions for a language model. \n",
    "# This can be used to guide a model's response, helping it understand the context and generate relevant and coherent language-based output.\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\",verbose=True)\n",
    "\n",
    "template = '''\n",
    "You're an experienced software engineer.\n",
    "Your task is to explain the {concept} in {code_language} code in a simple way.\n",
    "The explanation should be clear and concise, using simple language and examples if necessary.\n",
    "In few lines alone is fine.don't give long responses.\n",
    "The explanation should be easy to understand for someone who is not familiar with the concept.\n",
    "'''\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "prompt=prompt_template.format(concept=\"use of decorators\", code_language=\"python\")\n",
    "prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e39857ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decorators are a simple way to modify or enhance functions or classes in Python. They \"wrap\" a function/class with extra code, adding functionality without directly changing the original. Think of them as adding frosting to a cake.\n"
     ]
    }
   ],
   "source": [
    "output =llm.invoke(prompt)\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a31c2a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Why did the cat join the Red Cross? \\n\\nBecause he wanted to be a first-aid kit!', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run-a6fcc09a-ca3d-4b04-8979-2ed35cadbe6d-0', usage_metadata={'input_tokens': 16, 'output_tokens': 23, 'total_tokens': 39, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ChatPromptTemplate - These prompt templates are used to format a list of messages. These \"templates\" consist of a list of templates themselves.\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate([\n",
    "    (\"system\", \"You are a helpful assistant\"),\n",
    "    (\"user\", \"Tell me a joke about {topic}\")\n",
    "])\n",
    "prompt =prompt_template.format(topic=\"cats\")\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb3b9014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You respond only in JSON format.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Top 5 countries in Asia by population.', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,HumanMessagePromptTemplate,SystemMessagePromptTemplate\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(content='You respond only in JSON format.'),\n",
    "        HumanMessagePromptTemplate.from_template('Top {n} countries in {area} by population.')\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(n=5,area='Asia')\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "adb8c5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"top_5_asian_countries_by_population\": [\n",
      "    {\n",
      "      \"rank\": 1,\n",
      "      \"country\": \"India\",\n",
      "      \"population\": \"1,428,627,663\"\n",
      "    },\n",
      "    {\n",
      "      \"rank\": 2,\n",
      "      \"country\": \"China\",\n",
      "      \"population\": \"1,425,671,352\"\n",
      "    },\n",
      "    {\n",
      "      \"rank\": 3,\n",
      "      \"country\": \"Indonesia\",\n",
      "      \"population\": \"277,534,122\"\n",
      "    },\n",
      "    {\n",
      "      \"rank\": 4,\n",
      "      \"country\": \"Pakistan\",\n",
      "      \"population\": \"240,485,658\"\n",
      "    },\n",
      "    {\n",
      "      \"rank\": 5,\n",
      "      \"country\": \"Bangladesh\",\n",
      "      \"population\": \"172,954,319\"\n",
      "    }\n",
      "  ],\n",
      "  \"source\": \"United Nations, Department of Economic and Social Affairs, Population Division (2023). World Population Prospects 2022, Online Edition.\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "output = llm.invoke(messages)\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec173d1",
   "metadata": {},
   "source": [
    "#### Simple chains\n",
    "- [Chains](https://python.langchain.com/api_reference/langchain/chains.html) are a series of steps and actions. Chains allow us to combine multiple components together to solve a specific task and build an entire LLM application.\n",
    "- Refer to latest docs on how to implement both simple and [sequential](https://python.langchain.com/docs/how_to/sequence/#related) chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26ee3987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Setting Global Verbose ---\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "import langchain.globals\n",
    "print(\"\\n--- Setting Global Verbose ---\")\n",
    "langchain.globals.set_verbose(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32aff3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Decorators are a simple way to modify or enhance functions or methods in Python. They \"wrap\" a function with extra functionality, adding behavior before or after the original function runs, without directly changing the original function\\'s code. Think of them as adding frosting to a cake!'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain # deprecated\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "template = '''\n",
    "You're an experienced software engineer.\n",
    "Your task is to explain the {concept} in {code_language} code in a simple way.\n",
    "The explanation should be clear and concise, using simple language and examples if necessary.\n",
    "In few lines alone is fine.don't give long responses.\n",
    "The explanation should be easy to understand for someone who is not familiar with the concept.\n",
    "'''\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=['concept', 'code_language'],\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "# OutputParser that parses LLMResult into the top likely string.\n",
    "chain.invoke({'concept': 'decorators', 'code_language': 'python'})\n",
    "# print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59889f22",
   "metadata": {},
   "source": [
    "#### langchain agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9f62904",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_experimental.utilities import PythonREPL # Simulates a standalone Python REPL.\n",
    "# Create a new model by parsing and validating input data from keyword arguments.\n",
    "# reference doc : https://python.langchain.com/docs/integrations/tools/python/\n",
    "python_repl = PythonREPL()\n",
    "python_repl.run(\"print(1+1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f6b3cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[13, 26, 39, 52, 65, 78, 91]\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_repl.run('print([n for n in range(1,100) if n%13 ==0])')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7dc724a",
   "metadata": {},
   "source": [
    "#### Agents combine langchain tools and chains to create a single agent that can perform multiple tasks.\n",
    "- Agent is a class that uses an LLM to choose a sequence of actions to take.\n",
    "- In Chains, a sequence of actions is hardcoded. In Agents, a language model is used as a reasoning engine to determine which actions to take and in which order.\n",
    "- Agents select and use Tools and Toolkits for actions.\n",
    "[Reference Doc](https://python.langchain.com/api_reference/experimental/agents.html)\n",
    "- [Construct a python agent from an LLM and tool.](https://python.langchain.com/api_reference/experimental/agents/langchain_experimental.agents.agent_toolkits.python.base.create_python_agent.html#langchain_experimental.agents.agent_toolkits.python.base.create_python_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cce9cb35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to calculate the square root of 100. I can use the `math.sqrt()` function in python.\n",
      "Action: Python_REPL\n",
      "Action Input: `import math\n",
      "print(math.sqrt(100))`\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m10.0\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have calculated the square root of 100.\n",
      "Final Answer: 10.0\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'calculate the square root of 100', 'output': '10.0'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_experimental.agents.agent_toolkits import create_python_agent #Construct a python agent from an LLM and tool. - if we look at parameters in doc , we need PythonREPLTool\n",
    "from langchain_experimental.tools import PythonREPLTool #Tool for running python code in a REPL.\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI #Chat model for Google Generative AI.\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\",temperature=0.0)\n",
    "agent_executor = create_python_agent(llm=llm, tool=PythonREPLTool(), verbose=True)\n",
    "# tools are essential functions that agents can use to interact with the outside world.\n",
    "agent_executor.invoke(\"calculate the square root of 100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1efaf3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to calculate the value of 5.1 raised to the power of 7.3. I can use the python REPL to do this.\n",
      "Action: Python_REPL\n",
      "Action Input: `print(5.1 ** 7.3)`\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m146306.05007233328\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have calculated the value of 5.1 raised to the power of 7.3.\n",
      "Final Answer: 146306.05007233328\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = agent_executor.invoke(\"what is the answer to 5.1 ** 7.3?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ac3d570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'what is the answer to 5.1 ** 7.3?', 'output': '146306.05007233328'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0133d19e",
   "metadata": {},
   "source": [
    "#### Langchain tools\n",
    "- Langchain tools are like specialized apps for your LLM. They are tiny code modules that allow it to access information and services.\n",
    "- These tools connect your LLM to search engines, databases, APIs, and more, expanding its knowledge and capabilities.\n",
    "- let's explore langchain tools : [DuckDuckGo](https://pypi.org/project/duckduckgo-search/) - [Tool](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.ddg_search.tool.DuckDuckGoSearchResults.html) that queries the DuckDuckGo search API and returns the results in output_format.and Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1459bb3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The current president of the United States is Donald Trump, who assumed office on January 20, 2025. This web page provides a comprehensive list of all 47 presidents from George Washington to Donald Trump, with their portraits, terms, parties, and vice presidents. Donald Trump became the 47th president of the United States on January 20, 2025 (Credit: The Trump White House, Public Domain/ Wikimedia Commons) On January 20, 2025, Donald Trump was sworn in as the 47th President of the United States. He is only the second President to serve non-consecutive terms since Grover Cleveland in 1893. At 78 years ... WASHINGTON − Donald Trump was sworn in Monday as the 47th president of the United States, returning to the White House after overcoming four criminal indictments and two assassination attempts ... Donald Trump has officially become the 47th president of the United States. In a special ceremony called an inauguration , President Trump took over from Joe Biden as America's new leader. Donald Trump, who overcame impeachments, criminal indictments and a pair of assassination attempts to win another term in the White House, was sworn in Monday as the 47th U.S. president taking ...\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "search_tool = DuckDuckGoSearchRun()\n",
    "search_tool.run(\"Who is the current president of the United States?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c0cfc3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duckduckgo_search\n",
      "A wrapper around DuckDuckGo Search. Useful for when you need to answer questions about current events. Input should be a search query.\n"
     ]
    }
   ],
   "source": [
    "print(search_tool.name)\n",
    "print(search_tool.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8fde43f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snippet: The current president of the United States is Donald Trump, who assumed office on January 20, 2025. This web page provides a comprehensive list of all 47 presidents from George Washington to Donald Trump, with their portraits, terms, parties, and vice presidents., title: List of presidents of the United States - Wikipedia, link: https://en.wikipedia.org/wiki/List_of_presidents_of_the_United_States, snippet: Here is a list of the presidents and vice presidents of the United States along with their parties and dates in office., title: List of Presidents and Vice Presidents of the U.S. - ThoughtCo, link: https://www.thoughtco.com/presidents-and-vice-presidents-chart-4051729, snippet: Donald Trump was sworn in Monday as the 47th president of the United States in one of the most remarkable political comebacks in U.S. history., title: Trump sworn in as 47th president, declares 'America's decline is over', link: https://www.usatoday.com/story/news/politics/elections/2025/01/20/donald-trump-sworn-in-as-47-president-inauguration/77755765007/, snippet: Donald Trump became the 47th president of the United States on January 20, 2025 (Credit: The Trump White House, Public Domain/ Wikimedia Commons) On January 20, 2025, Donald Trump was sworn in as the 47th President of the United States. He is only the second President to serve non- consecutive terms since Grover Cleveland in 1893., title: Donald Trump Takes Office As The 47th President Of The United States, link: https://www.dogonews.com/2025/1/21/donald-trump-takes-office-as-the-47th-president-of-the-united-states\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools import  DuckDuckGoSearchResults\n",
    "search_tool = DuckDuckGoSearchResults()\n",
    "output = search_tool.run(\"Who is the current president of the United States?\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87180293",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import DuckDuckGoSearchAPIWrapper\n",
    "\n",
    "wrapper = DuckDuckGoSearchAPIWrapper(region=\"de-de\", max_results=3, safesearch='moderate')\n",
    "search = DuckDuckGoSearchResults(api_wrapper=wrapper)\n",
    "output = search.run('Berlin')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a70a1315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snippet: Berlin [bɛr'li:n] ist die Hauptstadt [10] und ein Land der Bundesrepublik Deutschland. [11] [12] Die Großstadt ist mit rund 3,7 Millionen Einwohnern [13] die bevölkerungsreichste und mit 891 Quadratkilometern die flächengrößte Gemeinde Deutschlands sowie die bevölkerungsreichste Stadt der Europäischen Union. [4], title: Berlin - Wikipedia, link: https://de.wikipedia.org/wiki/Berlin, snippet: Immer wieder eine Reise wert: Berlin ist im ständigen Wandel. Die Highlights und Neuheiten zwischen Ku'damm und Alexanderplatz, mit Karte. Die besten Aussichtsplätze und Sightseeing-Touren. Auf den Spuren der Berliner Mauer. Grünes Berlin am Tempelhofer Feld und im Park am Gleisdreieck, title: 20 Sehenswürdigkeiten in Berlin: Die besten Tipps für 2025 - ADAC, link: https://www.adac.de/reise-freizeit/reiseplanung/inspirationen/deutschland/sehenswuerdigkeiten-berlin/, snippet: Damit du aber auch sinnvoll deine Städtereise nach Berlin planen kannst und nicht die Hälfte deiner Zeit in der U-Bahn hockst, sagen wir dir, welche Sehenswürdigkeiten von Berlin beieinander liegen, wie hoch der Eintritt ist und was es überhaupt mit den bekanntesten Berliner Attraktionen auf sich hat., title: Berlin Sehenswürdigkeiten: Top-25-Liste mit Tipps & Bezirken, link: https://www.voucherwonderland.com/reisemagazin/top-20-sehenswuerdigkeiten-in-berlin/, snippet: Berlin ist ein Mosaik aus Vergangenheit und Zukunft, aus Grünflächen und urbanem Flair. Jeder Bezirk, jede Ecke zeigt ein anderes Gesicht dieser einzigartigen Metropole. Am Ende des Artikels findest du auch eine interaktive Karte mit den schönsten Orten in Berlin im Überblick., title: Berlin: 12 schöne Orte, die du sehen musst [mit Karte], link: https://phototravellers.de/berlin-schoenste-orte/\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a48ae553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snippet: Berlin [bɛr'li:n] ist die Hauptstadt [10] und ein Land der Bundesrepublik Deutschland. [11] [12] Die Großstadt ist mit rund 3,7 Millionen Einwohnern [13] die bevölkerungsreichste und mit 891 Quadratkilometern die flächengrößte Gemeinde Deutschlands sowie die bevölkerungsreichste Stadt der Europäischen Union. [4] \n",
      "Title : Berlin - Wikipedia \n",
      "Link: \n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Snippet: Immer wieder eine Reise wert: Berlin ist im ständigen Wandel. Die Highlights und Neuheiten zwischen Ku'damm und Alexanderplatz, mit Karte. Die besten Aussichtsplätze und Sightseeing-Touren. Auf den Spuren der Berliner Mauer. Grünes Berlin am Tempelhofer Feld und im Park am Gleisdreieck \n",
      "Title : 20 Sehenswürdigkeiten in Berlin: Die besten Tipps für 2025 - ADAC \n",
      "Link: \n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Snippet: Damit du aber auch sinnvoll deine Städtereise nach Berlin planen kannst und nicht die Hälfte deiner Zeit in der U-Bahn hockst, sagen wir dir, welche Sehenswürdigkeiten von Berlin beieinander liegen, wie hoch der Eintritt ist und was es überhaupt mit den bekanntesten Berliner Attraktionen auf sich hat. \n",
      "Title : Berlin Sehenswürdigkeiten: Top-25-Liste mit Tipps & Bezirken \n",
      "Link: \n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Snippet: Berlin ist ein Mosaik aus Vergangenheit und Zukunft, aus Grünflächen und urbanem Flair. Jeder Bezirk, jede Ecke zeigt ein anderes Gesicht dieser einzigartigen Metropole. Am Ende des Artikels findest du auch eine interaktive Karte mit den schönsten Orten in Berlin im Überblick. \n",
      "Title : Berlin: 12 schöne Orte, die du sehen musst [mit Karte] \n",
      "Link: \n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "pattern = r'snippet: (.*?), title: (.*?), link: (.*?)'\n",
    "matches = re.findall(pattern,output,re.DOTALL)\n",
    "\n",
    "for snippet, title, link in matches:\n",
    "    print(f\"Snippet: {snippet} \\nTitle : {title} \\nLink: {link}\\n\")\n",
    "    print('---'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e587b8e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Page: Vector database\\nSummary: A vector database, vector store or vector search engine is a database that can store vectors (fixed-length lists of numbers) along with other data items. Vector databases typically implement one or more Approximate Nearest Neighbor algorithms, so that one can search the database with a query vector to retrieve the closest matching database records.\\nVectors are mathematical representations of data in a high-dimensional space. In this space, each dimension corresponds to a feature of the data, with the number of dimensions ranging from a few hundred to tens of thousands, depending on the complexity of the data being represented. A vector\\'s position in this space represents its characteristics. Words, phrases, or entire documents, as well as images, audio, and other types of data, can all be vectorized.\\nThese feature vectors may be computed from the raw data using machine learning methods such as feature extraction algorithms, word embeddings or deep learning networks. The goal is that semantically similar data items receive feature vectors close to each other.\\nVector databases can be used for similarity search, semantic search, multi-modal search, recommendations engines, large language models (LLMs), object detection,  etc.\\nVector databases are also often used to implement retrieval-augmented generation (RAG), a method to improve domain-specific responses of large language models. The retrieval component of a RAG can be any search system, but is most often implemented as a vector database. Text documents describing the domain of interest are collected, and for each document or document section, a feature vector (known as an \"embedding\") is computed, typically using a deep learning network, and stored in a vector database. Given a user prompt, the feature vector of the prompt is computed, and the database is queried to retrieve the most relevant documents. These are then automatically added into the context window of the large language model, and the large language model proceeds to create a response to the prompt given this context.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "api_wrapper = WikipediaAPIWrapper(top_k_results=1,wiki_client=None,doc_content_chars_max=5000)\n",
    "wiki= WikipediaQueryRun(api_wrapper=api_wrapper)\n",
    "wiki.invoke({'query': 'llamaindex'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7fe8c5e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Page: Gemini (chatbot)\\nSummary: Gemini, formerly known as Bard, is a generative artificial intelligence chatbot developed by Google. Based on the large language model (LLM) of the same name, it was launched in 2023 in response to the rise of OpenAI\\'s ChatGPT. It was previously based on the LaMDA and PaLM LLMs.\\nLaMDA had been developed and announced in 2021, but it was not released to the public out of an abundance of caution. OpenAI\\'s launch of ChatGPT in November 2022 and its subsequent popularity caught Google executives off-guard, prompting a sweeping response in the ensuing months. After mobilizing its workforce, the company launched Bard in a limited capacity in March 2023 before expanding to other countries in May. Bard took center stage during the 2023 Google I/O keynote in May and was upgraded to the Gemini LLM in December. In February 2024, Bard and Duet AI, another artificial intelligence product from Google, were unified under the Gemini brand, coinciding with the launch of an Android app.\\nGemini has received lukewarm responses. It became the center of controversy in February 2024, when social media users reported that it was generating historically inaccurate images of historical figures as people of color, with people commenting on its bias as \"wokeness\".'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki.invoke('Google Gemini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b164523",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
